{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from contextlib import contextmanager\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "import threading\n",
    "import timeit\n",
    "import _thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Type car brand to scrap data from Allegro (select from: Audi/ BMW/ Skoda/ Honda/ Ford/ Mercedes/ Subaru/ Seat)\")\n",
    "car_model=input()\n",
    "try_link=\"https://allegro.pl/kategoria/samochody-osobowe-4029?string=\"+car_model+\"&bmatch=baseline-product-cl-eyesa2-engag-dict45-aut-1-4-0605\"\n",
    "try_link\n",
    "type(try_link)\n",
    "html = urlopen(try_link)\n",
    "bs = BeautifulSoup(html, 'lxml')\n",
    "for item in bs.findAll(\"a\",href=True)[:3] :\n",
    "    print(item, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in bs.findAll(\"a\", href=re.compile(\"allegro.pl/ogloszenie\"))[:20]:\n",
    "    print(item.attrs[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_offers(try_link):\n",
    "    html = urlopen(try_link)\n",
    "    bs = BeautifulSoup(html, 'lxml')\n",
    "    offer_list = []\n",
    "    for item in bs.findAll(\"a\", href=re.compile(\"allegro.pl/ogloszenie\")):\n",
    "        offer_list.append(item.attrs[\"href\"])\n",
    "    offer_list = list(set(offer_list))\n",
    "    return (offer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in bs.findAll(\"a\", {\"aria-label\":re.compile(\"przejdź do strony\")}):\n",
    "    print(item.attrs[\"href\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in bs.findAll(\"a\", {\"aria-label\":re.compile(\"następna\")}):\n",
    "    print(item.attrs[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_page(try_link):\n",
    "    html = urlopen(try_link)\n",
    "    bs = BeautifulSoup(html, 'lxml')\n",
    "    next_page = bs.findAll(\"a\", {\"aria-label\": re.compile(\"następna\")})[0].attrs[\"href\"]\n",
    "    return (next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_following(try_link,n):\n",
    "    page_list=[try_link]\n",
    "    link_temp=try_link\n",
    "    print(\"Page 0 is added to all pages list:\\n{}\\n\".format(try_link))\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        try:\n",
    "            next_page=get_next_page(link_temp)            \n",
    "            print(\"Page {} added to total pages list:\\n{}\\n\".format(i+1,next_page))            \n",
    "            link_temp=next_page\n",
    "            page_list.append(next_page)\n",
    "        except:\n",
    "            break\n",
    "    return(page_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_list=get_n_following(try_link,3)\n",
    "len(page_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_offers=[]\n",
    "for i in range(0,len(page_list)-1):\n",
    "    print(\"Extracting Allegro offers from selected link\")\n",
    "    print(page_list[i])\n",
    "    all_offers=all_offers+get_page_offers(page_list[i])\n",
    "    print(\"Total cumulative number of offers={}\\n\".format(len(all_offers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer=all_offers[6]\n",
    "offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(offer)\n",
    "bs = BeautifulSoup(html, 'lxml')\n",
    "bs.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=re.findall(\"\\[([^]]+)\\]\",bs.script.string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramDict=json.loads(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ticket=paramDict[\"idItem\"]\n",
    "Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=paramDict[\"price\"]\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OEMdetails=paramDict[\"headNavigation\"]\n",
    "OEMdetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OEMdetails=re.findall((\"(?<=Samochody\\|Osobowe)(?s)(.*$)\"),OEMdetails)[0]\n",
    "OEM, Model, Serie=(OEMdetails.split(\"|\"))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"OEM\"],data[\"Model\"],data[\"Serie\"]=(OEMdetails.split(\"|\"))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Ticket\"]=Ticket\n",
    "data[\"Price\"]=paramDict[\"price\"]\n",
    "data[\"Title\"]=bs.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict=bs.findAll(\"script\",{'data-serialize-box-id':'9xQB2iYQTKGcjrnbLd_GVA==kQ32FRhOQcqYmKhfpeU6lQ=='})[0].string\n",
    "dataDict=json.loads(dataDict)\n",
    "dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict.keys()\n",
    "dataDict[\"groups\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict[\"groups\"][0]['singleValueParams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(dataDict[\"groups\"][0]['singleValueParams'])):\n",
    "    feature=dataDict[\"groups\"][0]['singleValueParams'][i][\"name\"]\n",
    "    value=dataDict[\"groups\"][0]['singleValueParams'][i][\"value\"][\"name\"]\n",
    "    data[feature]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bs.title.string)\n",
    "print(\"\\n\")\n",
    "for i in range(0,len(dataDict[\"groups\"][0]['singleValueParams'])):\n",
    "    feature=dataDict[\"groups\"][0]['singleValueParams'][i][\"name\"]\n",
    "    value=dataDict[\"groups\"][0]['singleValueParams'][i][\"value\"][\"name\"]\n",
    "    print(\"{}={}\".format(feature, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_data(link):\n",
    "    html = urlopen(link)\n",
    "    bs = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # Extracting key offer parameters \n",
    "    \n",
    "    key_data=re.findall(\"\\[([^]]+)\\]\",bs.script.string)[0]\n",
    "    key_data=json.loads(key_data)\n",
    "    \n",
    "    OEMdetails=key_data[\"headNavigation\"]  \n",
    "    OEMdetails=re.findall((\"(?<=Samochody\\|Osobowe)(?s)(.*$)\"),OEMdetails)[0]\n",
    "    \n",
    "    dataDict={}\n",
    "    \n",
    "    if len((OEMdetails.split(\"|\"))[1:])==3:\n",
    "    \n",
    "        dataDict[\"OEM\"],dataDict[\"model\"],dataDict[\"serie\"]=(OEMdetails.split(\"|\"))[1:]\n",
    "    elif len((OEMdetails.split(\"|\"))[1:])==2:\n",
    "        dataDict[\"OEM\"],dataDict[\"model\"]=(OEMdetails.split(\"|\"))[1:3]\n",
    "    else:\n",
    "        dataDict[\"OEM\"]=(OEMdetails.split(\"|\"))[1]\n",
    "        \n",
    "    dataDict[\"Ticket\"]=key_data[\"idItem\"]\n",
    "    dataDict[\"Price\"]=key_data[\"price\"]    \n",
    "    dataDict[\"Title\"]=bs.title.string\n",
    "    dataDict[\"Download_date\"]=str(datetime.now())\n",
    "    \n",
    "    #Extracting offer details \n",
    "    \n",
    "    details=bs.findAll(\"script\",{'data-serialize-box-id':'9xQB2iYQTKGcjrnbLd_GVA==kQ32FRhOQcqYmKhfpeU6lQ=='})[0].string\n",
    "    details=json.loads(details)\n",
    "    offer_details=details[\"groups\"][0]['singleValueParams']\n",
    "    \n",
    "    for i in range(0,len(offer_details)):\n",
    "        feature=offer_details[i][\"name\"]\n",
    "        value=offer_details[i][\"value\"][\"name\"]\n",
    "        dataDict[feature]=value \n",
    "    return(dataDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer=all_offers[0]\n",
    "offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract_data(offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutException(Exception):\n",
    "    def __init__(self, msg=''):\n",
    "        self.msg = msg\n",
    "\n",
    "@contextmanager\n",
    "def time_limit(seconds, msg=''):\n",
    "    timer = threading.Timer(seconds, lambda: _thread.interrupt_main())\n",
    "    timer.start()\n",
    "    try:\n",
    "        yield\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        timer.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now(pytz.timezone('Europe/Amsterdam')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestring=str(datetime.now(pytz.timezone('Europe/Amsterdam')))[11:19]\n",
    "timestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestring=timestring.replace(\":\",\"-\")\n",
    "timestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Offer_database(offers_list,time,directory):  \n",
    "    \n",
    "    data=[]\n",
    "    failed_extractions=0\n",
    "    \n",
    "    for i in range(0, len(all_offers)):\n",
    "        \n",
    "        #Each loops tries to extract data from one offer until \"time\" amount of seconds is exceeded. Exceeding time limit \n",
    "        #passes the loop to the next offer\n",
    "        \n",
    "        with time_limit(time, 'sleep'):\n",
    "            try:\n",
    "                offer=offers_list[i]\n",
    "                if np.mod(i,100)==0:\n",
    "                    print(\"Extraction: {}/{} at:{}\".format(i+1,len(offers_list),str(datetime.now())[:-7] ))\n",
    "                offer_data=Extract_data(offer)\n",
    "                data.append(offer_data)\n",
    "            except:\n",
    "                print(\"Extraction: {}/{}  !!FAILED!!scrapping took too long\".format(i+1,len(offers_list)))\n",
    "                failed_extractions=failed_extractions+1\n",
    "                pass\n",
    "            \n",
    "    # After scraping data the summary of results is printed.\n",
    "    \n",
    "    print(\"\\n------------------------------------------\\n\")\n",
    "    print(\"Sucessfully Extracted: {}/{} offers \\nErrors:{}\".format((i-failed_extractions+1),i+1,failed_extractions))\n",
    "     \n",
    "    # Data is converted from json to DataFrame and saved as a csv file in given directory\n",
    "    \n",
    "    data_json=json.dumps(data)\n",
    "    df=pd.read_json(data_json, orient='records')\n",
    "    timestring=str(datetime.now(pytz.timezone('Europe/Amsterdam')))[11:19]\n",
    "    timestring=timestring.replace(\":\",\"-\")\n",
    "    timestring\n",
    "    print(\"Saving {} offers at{}\".format(i-failed_extractions+1,directory+\"/\"+timestring+\".csv\"))\n",
    "   \n",
    "    df.to_csv(directory+\"/\"+timestring+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offer_database(all_offers,5,'/home/monika/Pulpit/SCRAP/databaza_monika')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_offers(offer_list, batch_size):\n",
    "    offers_split=[offer_list[x:x+batch_size] for x in range(0, len(offer_list), batch_size)]\n",
    "    return(offers_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Offer_database_batches(offers_list, time, batch_size, folder_name):\n",
    "    import os\n",
    "    todayDate = str(datetime.utcnow().date())\n",
    "    directory = '/home/monika/Pulpit/SCRAP/database_allegro_' + folder_name + \"_\" + todayDate\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    offers_split = split_offers(offers_list, batch_size)\n",
    "    for i in range(0, len(offers_split)):\n",
    "        print(\"Starting Batch no.{}/{}\\n\".format(i + 1, len(offers_split)))\n",
    "        offers = offers_split[i]\n",
    "        Offer_database(offers, time, directory)\n",
    "        print(\"\\n--------\\nFinished Batch no.{}/{}\\n\\n\".format(i + 1,len(offers_split)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=str(car_model)+\"_database\"\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offer_database_batches(all_offers,20,100,folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
